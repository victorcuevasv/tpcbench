import picocli.CommandLine
import picocli.CommandLine.{Command, Option}
import java.util.concurrent.Callable
import java.time.Instant
import java.net.URL

@Command(name = "tpcdsbench", mixinStandardHelpOptions = true, version = Array("tpcdsbench 1.0"),
  description = Array("Executes the TPC-DS benchmark power test"))
class TpcdsBench extends Callable[Int] {

  val timestamp = Instant.now.getEpochSecond
  @Option(names = Array("--exec-flags"), description = Array("Flags for the execution of different tests create_db|load|power"))
  private var flags = "111"
  @Option(names = Array("--scale-factor"), description = Array("Scale factor in GB for the benchmark"))
  private var scaleFactor = 1
  @Option(names = Array("--raw-data-url"), description = Array("URL of the input raw TPC-DS CSV data"))
  private var rawDataURL = s"s3://tpcds-data-1713123644/${scaleFactor}GB/"
  @Option(names = Array("--warehouse-base-url"), description = Array("Base URL for the generated TPC-DS tables data"))
  private var warehouseBaseURL = s"s3://tpcds-warehouses-1713123644/"
  @Option(names = Array("--gen-data-tag"), description = Array("Unix timestamp identifying the generated data"))
  var genDataTag = timestamp
  @Option(names = Array("--run-exp-tag"), description = Array("Unix timestamp identifying the experiment"))
  var runExpTag = timestamp
  @Option(names = Array("--file-format"), description = Array("File format to use for the tables"))
  var format = "delta"
  val dbName = s"tpcds_sf${scaleFactor}_${genDataTag}"
  val whLocation = TpcdsBenchUtil.addPathToURI(warehouseBaseURL, dbName)

  //Fact Tables partition keys
  val partitionKeys = Map (
    "catalog_returns" -> "cr_returned_date_sk",
    "catalog_sales" -> "cs_sold_date_sk",
    "inventory" -> "inv_date_sk",
    "store_returns" -> "sr_returned_date_sk",
    "store_sales" -> "ss_sold_date_sk",
    "web_returns" -> "wr_returned_date_sk",
    "web_sales" -> "ws_sold_date_sk"
  )

  def sql(stmt:String) = {
    println(stmt)
  }

  def call(): Int = {
    runTests()
    0
  }

  def runTests() = {
    println(s"Running the TPC-DS benchmark at the ${scaleFactor} scale factor.")
    if ( flags.charAt(0) == '1' )
      createDatabase()
    if ( flags.charAt(1) == '1')
      runLoadTest()
    if ( flags.charAt(2) == '1')
      runPowerTest()
  }

  def createDatabase() = {
    println(s"Creating database ${dbName}.")
    sql(s"DROP DATABASE IF EXISTS ${dbName}")
    sql(s"CREATE DATABASE IF NOT EXISTS ${dbName}")
  }

  def useDatabase() = {
    sql(s"USE ${dbName}")
  }

  def runLoadTest() = {
    println(s"Running the TPC-DS benchmark load test at the ${scaleFactor} scale factor.")
    useDatabase()
    val schemasMap = new TPCDS_Schemas().tpcdsSchemasMap
    val tableNames = schemasMap.keys.toList.sorted
    for (tableName <- tableNames) {
      loadTable(tableName, schemasMap(tableName))
    }
  }

  def loadTable(schema: String, tableName: String) = {
    val banner = schema.split("\n")(0) + "..."
    println(s"START: $banner")  
    try {
      //sql(str)
      println(s"END: $banner" )
    }
    catch {
      case e: Exception => {  
        println(e.getMessage)
      }
    }
  }

  def runPowerTest() = {

  }

  // Parse the schema of a given table out of a "create table" query generated by the tpcds toolkit.
  // Returns an array of tuples (Attribute, Type)
  def parseSchemaFromSQL(tableName: String) : Array[(String, String)]= {
    tableName
    .split("\n")    // Split the schema into lines
    .drop(2)        // Drop the CREATE TABLE and the parenthesis on the first two lines
    .map(           
      _.split(" +") // Split the lines by any amount of spaces generating arrays of strings (tokens)
      .drop(1)      // Drop the initial whitespace
      .take(2)      // Take only the first two elements as we do only want the column name and type
    ).filter( // Filter out empty lines and primary key lines (if any)
      tokens => tokens.length > 0 && tokens(0) != "primary")
    .map( // Generate the (attribute, type) pairs, changing integer into int when applicable
      tokens => if (tokens(1) == "integer") (tokens(0), "int") else (tokens(0), tokens(1))) 
  }

  // Generate a SQL statement to create an external table over the raw CSV data
  def genExtTableStmt(tableName: String, whLocation: String) = {
    var sb = new StringBuilder(s"CREATE EXTERNAL TABLE ${tableName}_ext\n(\n")
    sb ++= parseSchemaFromSQL(tableName).map(t=> s"    ${t._1} ${t._2}").mkString(",\n")
    sb ++= s"""
    )
    ROW FORMAT DELIMITED FIELDS TERMINATED BY '\001'
    STORED AS TEXTFILE
    LOCATION '${whLocation}/${tableName}'
    """
    sb.toString()
  }

  // Generate a SQL statement to create a warehouse table to store the data in the desired format
  def genWarehouseTableStmt(tableName: String, whLocation: String, 
    partitionKeys: Map[String, String], format: String) = {
    var sb = new StringBuilder(s"CREATE TABLE ${tableName}\n(\n")
    sb ++= parseSchemaFromSQL(tableName).map(t=> s"    ${t._1} ${t._2}").mkString(",\n")
    sb ++= s"""
    )
    USING ${format}
    OPTIONS('compression'='lzo')
    """
    if (partitionKeys.contains(tableName)) sb ++= s"PARTITIONED BY (${partitionKeys(tableName)})\n"
    sb ++= s"LOCATION '${whLocation}/${tableName}'"
    sb.toString()
  }

  // Generate a SQL statement to insert the data from the external table into the warehouse table
  def genInsertStmt(tableName: String, partitionKeys: Map[String, String]) = {
    var sb = new StringBuilder(s"INSERT OVERWRITE TABLE ${tableName} SELECT")
    // If the table is partitioned, the attributes need to be listed with the partition attributes at the end
    if (partitionKeys.contains(tableName)) {
      sb ++= "\n"                                            // Add a new line if we have to list the attributes
      sb ++= parseSchemaFromSQL(tableName)       // Get the list of attributes
      .map(_._1)                                             // Select only the attribute names
      .filter(_ != partitionKeys(tableName))                 // Filter out the partition key
      .mkString(",\n")                                       // Concatenate into a string
      sb ++= s",\n${partitionKeys(tableName)}\n"             // Add the partition key to the end of the list
    } else sb ++= " * "                                      // Select everything if the table is not partitioned
    sb ++= s"FROM ${tableName}_ext"
    // If the table is partitioned add a DISTRIBUTE BY directive
    if (partitionKeys.contains(tableName)) sb ++= s"\nDISTRIBUTE BY ${partitionKeys(tableName)}"
    sb.toString()
  }
  

}

object TpcdsBench {
  def main(args: Array[String]): Unit = {
    System.exit(new CommandLine(new TpcdsBench()).execute(args: _*))
  }
}
