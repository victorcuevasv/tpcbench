
#SSH access to the cluster master node (does not work, has to be enabled in AWS).

ssh -p 2200 -i id_rsa ubuntu@ec2-34-219-76-81.us-west-2.compute.amazonaws.com

#Install pip3

apt-get --assume-yes install python3-pip

#Update pip3.

pip3 install --upgrade pip

#Install dbfs cli

pip install databricks-cli

#Configure the dbfs cli. (the \n character separates the host and token)

printf 'https://dbc-....faef.cloud.databricks.com\ndapib5b...90da294d' | dbfs configure --token




Spark example.

#Copy the results file.

dbfs cp  dbfs:/root/pi_dataframe.txt/part-00000-tid-4746470960100063989-bd257991-ef9c-477a-ba8f-15b4bb89006a-4-c000.txt  ./pi_dataframe.txt        


#Copy data volume.

dbfs cp -r data dbfs:/data


#Metastore jars.

/local_disk0/tmp/hive-v2_3-c222c891-2fd0-422d-856e-4063d6b838c5

%sh cp -r /local_disk0/tmp/hive-v2_3-c222c891-2fd0-422d-856e-4063d6b838c5 /dbfs/hive_metastore_jar

dbfs cp init_scriptHiveJars.sh dbfs:/databricks/scripts/init_scriptHiveJars.sh

spark.sql.hive.metastore.jars /databricks/hive_metastore_jars/*

19/04/09 15:56:15 INFO IsolatedClientLoader: Initiating download of metastore jars from maven. 
This may take a while and is not recommended for production use. Please follow the instructions 
here: https://docs.databricks.com/user-guide/advanced/external-hive-metastore.html#spark-options 
on how to download the jars just once and use them in your cluster configuration. A log message 
beginning with 'Downloaded metastore jars' will print once the download is complete.


spark.sql.hive.metastore.version 2.3.0
spark.sql.hive.metastore.jars /databricks/hive_metastore_jars/*
hive.metastore.schema.verification true
hive.metastore.schema.verification.record.version 2.3.0

#From the singlenode docker setup.

psql metastore root

\dt    (list the tables)

metastore=# SELECT * FROM "VERSION";
 VER_ID | SCHEMA_VERSION |      VERSION_COMMENT       
--------+----------------+----------------------------
      1 | 2.3.0          | Hive release version 2.3.0
      
      
      
%sh cat /databricks/hive/conf/hive-site.xml


<?xml version="1.0" encoding="UTF-8"?>
<configuration>
   <property>
      <name>javax.jdo.option.ConnectionURL</name>
      <value>jdbc:mariadb://mdpartyyphlhsp.caj77bnxuhme.us-west-2.rds.amazonaws.com:3306/organization538214631695239?trustServerCertificate=true&amp;useSSL=true</value>
      <description>JDBC connect string for a JDBC metastore</description>
   </property>
   <property>
      <name>javax.jdo.option.ConnectionDriverName</name>
      <value>org.mariadb.jdbc.Driver</value>
      <description>Driver class name for a JDBC metastore</description>
   </property>
   <property>
      <name>javax.jdo.option.ConnectionUserName</name>
      <value>woA71HHf3Yvu6VWs</value>
      <description>Username to use against metastore database</description>
   </property>
   <property>
      <name>javax.jdo.option.ConnectionPassword</name>
      <value>ep840EV9gKRZvonicYNJSH5paWFIDzkJdxGsjU98</value>
      <description>Password to use against metastore database</description>
   </property>
   <!-- If the following two properties are not set correctly, the metastore will attempt to initialize its schema upon startup -->
   <property>
      <name>datanucleus.autoCreateSchema</name>
      <value>false</value>
   </property>
   <property>
      <name>datanucleus.fixedDatastore</name>
      <value>true</value>
   </property>
   <property>
      <name>datanucleus.connectionPool.minPoolSize</name>
      <value>0</value>
   </property>
   <property>
      <name>datanucleus.connectionPool.initialPoolSize</name>
      <value>0</value>
   </property>
   <property>
      <name>datanucleus.connectionPool.maxPoolSize</name>
      <value>1</value>
   </property>
   <property>
      <name>hive.stats.autogather</name>
      <value>false</value>
   </property>
   <property>
      <name>mapred.reduce.tasks</name>
      <value>100</value>
   </property>
   <!-- To mitigate the problem of PROD-4498 and per HIVE-7140, we need to bump the timeout. Since the default value of this property used by Impala is 3600 seconds, we will use this value for actual deployment (http://www.cloudera.com/content/cloudera/en/documentation/core/latest/topics/cm_props_cdh530_impala.html). -->
   <property>
      <name>hive.metastore.client.socket.timeout</name>
      <value>3600</value>
   </property>
   <property>
      <name>hadoop.tmp.dir</name>
      <value>/local_disk0/tmp</value>
   </property>
   <property>
      <name>hive.metastore.client.connect.retry.delay</name>
      <value>10</value>
   </property>
   <property>
      <name>hive.metastore.failure.retries</name>
      <value>30</value>
   </property>
</configuration>



Caused by: MetaException(message:Hive Schema version 2.3.0 does not match metastore's schema version 0.13.0 Metastore is not upgraded or corrupt)    
      

ssh ubuntu@ec2-34-214-164-80.us-west-2.compute.amazonaws.com -p 2200 -i id_rsa -o StrictHostKeyChecking=no


mysql --host=mdpartyyphlhsp.caj77bnxuhme.us-west-2.rds.amazonaws.com --user=woA71HHf3Yvu6VWs --password=ep840EV9gKRZvonicYNJSH5paWFIDzkJdxGsjU98      




CREATE TEMPORARY TABLE dev_user_login 
(event_name STRING,  datetime TIMESTAMP,  ip_address STRING,  acting_user_id STRING)
USING org.apache.spark.sql.parquet
OPTIONS (
  path "examples/src/main/resources/people.parquet"
)



create external table reason_ext2 (r_reason_sk int, r_reason_id string, r_reason_desc string ) ROW FORMAT DELIMITED FIELDS TERMINATED BY '' STORED AS TEXTFILE LOCATION 'dbfs:/temporal/1GB/reason'


create table reason 
(
    r_reason_sk               int                           ,
    r_reason_id               varchar(16)                      ,
    r_reason_desc             varchar(100)                      
) 
USING org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat








         



