
#SSH access to the cluster master node (does not work, has to be enabled in AWS).

ssh -p 2200 -i id_rsa ubuntu@ec2-34-219-76-81.us-west-2.compute.amazonaws.com

#Install pip3

apt-get --assume-yes install python3-pip

#Update pip3.

pip3 install --upgrade pip

#Install dbfs cli

pip install databricks-cli

#Configure the dbfs cli. (the \n character separates the host and token)

printf 'https://dbc-....faef.cloud.databricks.com\ndapib5b...90da294d' | dbfs configure --token




Spark example.

#Copy the results file.

dbfs cp  dbfs:/root/pi_dataframe.txt/part-00000-tid-4746470960100063989-bd257991-ef9c-477a-ba8f-15b4bb89006a-4-c000.txt  ./pi_dataframe.txt        



#Metastore jars.

/local_disk0/tmp/hive-v2_3-c222c891-2fd0-422d-856e-4063d6b838c5

%sh cp -r /local_disk0/tmp/hive-v2_3-c222c891-2fd0-422d-856e-4063d6b838c5 /dbfs/hive_metastore_jar

dbfs cp init_scriptHiveJars.sh dbfs:/databricks/scripts/init_scriptHiveJars.sh

spark.sql.hive.metastore.jars /databricks/hive_metastore_jars/*

19/04/09 15:56:15 INFO IsolatedClientLoader: Initiating download of metastore jars from maven. 
This may take a while and is not recommended for production use. Please follow the instructions 
here: https://docs.databricks.com/user-guide/advanced/external-hive-metastore.html#spark-options 
on how to download the jars just once and use them in your cluster configuration. A log message 
beginning with 'Downloaded metastore jars' will print once the download is complete.








