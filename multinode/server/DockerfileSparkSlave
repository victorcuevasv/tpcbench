FROM ubuntujavahadoop:dev

USER root

ARG APACHE_MIRROR=archive.apache.org
ARG HADOOP_VERSION=2.7.7
ARG SPARK_VERSION=2.4.4

#Add the generated key to the authorized set.
#The ssh server has been installed in the ubuntujavahadoop image.

COPY ssh /root/.ssh

RUN chmod 600 /root/.ssh/id_rsa

RUN cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
    
#The configuration file will enable passwordless login to nodes
#and without confirmation prompt.
    
COPY conf/ssh_config /root/.ssh/config

#Add the Hadoop installation directory variable and update the path.
#The hadoop files have been downloaded for the ubuntujavahadoop image.

ENV HADOOP_HOME /opt/hadoop-$HADOOP_VERSION
ENV PATH="${PATH}:/opt/hadoop-$HADOOP_VERSION/bin:/opt/hadoop-$HADOOP_VERSION/sbin"

#Copy the Hadoop configuration files.
#The owner of the rest of the hadoop files has been changed in the ubuntujavahadoop image.

COPY etc_hadoop/* /opt/hadoop-$HADOOP_VERSION/etc/hadoop/
COPY conf/slaves /opt/hadoop-$HADOOP_VERSION/etc/hadoop/
RUN chown -R hadoop:hadoop /opt/hadoop-$HADOOP_VERSION/etc/hadoop/

#Download and decompress Spark.
#Use the version prebuilt for Hadoop, spark-sql does not work in the version without Hadoop.

RUN wget -q -P /opt http://$APACHE_MIRROR/dist/spark/spark-$SPARK_VERSION/spark-$SPARK_VERSION-bin-hadoop2.7.tgz && \
    tar xzf /opt/spark-$SPARK_VERSION-bin-hadoop2.7.tgz -C /opt && \
    rm -f /opt/spark-$SPARK_VERSION-bin-hadoop2.7.tgz
    
#Add the Spark installation directory variable and update the path.

ENV SPARK_HOME /opt/spark-$SPARK_VERSION-bin-hadoop2.7
ENV PATH="${PATH}:/opt/spark-$SPARK_VERSION-bin-hadoop2.7/bin"

#Add the Hadoop jars to the Spark classpath.

ENV SPARK_DIST_CLASSPATH="$HADOOP_HOME/etc/hadoop/*:$HADOOP_HOME/share/hadoop/common/lib/*:$HADOOP_HOME/share/hadoop/common/*:$HADOOP_HOME/share/hadoop/hdfs/*:$HADOOP_HOME/share/hadoop/hdfs/lib/*:$HADOOP_HOME/share/hadoop/hdfs/*:$HADOOP_HOME/share/hadoop/yarn/lib/*:$HADOOP_HOME/share/hadoop/yarn/*:$HADOOP_HOME/share/hadoop/mapreduce/lib/*:$HADOOP_HOME/share/hadoop/mapreduce/*:$HADOOP_HOME/share/hadoop/tools/lib/*"   

#Copy the initialization script for Hadoop, Hive, Presto and make it executable.

COPY startscripts/startSparkSlave.sh /startSparkSlave.sh

RUN chmod +x /startSparkSlave.sh

CMD ["bash"]

ENTRYPOINT [ "bash", "-c", "/startSparkSlave.sh" ]

